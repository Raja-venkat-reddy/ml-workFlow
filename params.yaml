val_size: 0.2
random_state: 42
test_size: 0.2

# Input feature columns (18 spectral channels)
features:
  - Channel_410_Mean
  - Channel_435_Mean
  - Channel_460_Mean
  - Channel_485_Mean
  - Channel_510_Mean
  - Channel_535_Mean
  - Channel_560_Mean
  - Channel_585_Mean
  - Channel_610_Mean
  - Channel_645_Mean
  - Channel_680_Mean
  - Channel_705_Mean
  - Channel_730_Mean
  - Channel_760_Mean
  - Channel_810_Mean
  - Channel_860_Mean
  - Channel_900_Mean
  - Channel_940_Mean

# Regression targets (19 outputs); exclude classification/text columns
targets:
  - Nitrogen_kg_ha
  - Phosphorus_kg_ha
  - Potassium_kg_ha
  - Organic_Carbon_%
  - Boron_ppm
  - Calcium_ppm
  - Copper_ppm
  - Iron_ppm
  - Magnesium_ppm
  - Sulfur_ppm
  - Zinc_ppm
  - Electrical_Conductivity_dSm
  - Water_Retention_10kPa
  - Water_Retention_1500kPa
  - Water_Retention_33kPa
  - Sand_Content
  - Clay_Content
  - Silt_Content
  - pH

# Global training limits
max_trials: 50
timeout_sec: 600

# Evaluation thresholds to decide re-train/fine-tune
min_r2: 0.85
max_rmse: 10.0

# Per-model default params (used when no tuning)
models:
  LinearRegression: {}
  Ridge: {alpha: 1.0}
  Lasso: {alpha: 0.001}
  ElasticNet: {alpha: 0.001, l1_ratio: 0.5}
  SVR: {C: 1.0, epsilon: 0.1, kernel: rbf}
  RandomForestRegressor: {n_estimators: 200, max_depth: null}
  ExtraTreesRegressor: {n_estimators: 300, max_depth: null}
  GradientBoostingRegressor: {n_estimators: 300, learning_rate: 0.05, max_depth: 3}
  XGBRegressor: {n_estimators: 400, learning_rate: 0.05, max_depth: 6}
  KNeighborsRegressor: {n_neighbors: 7, weights: distance}
